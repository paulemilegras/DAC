{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, LassoCV\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import norm\n",
    "from sklearn.cluster import KMeans\n",
    "import random\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from gurobipy import *\n",
    "\n",
    "# suppress all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of items\n",
    "n = 20\n",
    "\n",
    "# number of features\n",
    "d = 5\n",
    "\n",
    "# number of observations for each item\n",
    "obs = 10\n",
    "\n",
    "# number of clusters\n",
    "z = 2\n",
    "\n",
    "# number of trials\n",
    "T = 100\n",
    "\n",
    "# noise\n",
    "sigma = 1\n",
    "# prob\n",
    "p, q = 1/3, 1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_models_upd(Ru,Rl):\n",
    "    \n",
    "\n",
    "    r2_alg_t, r2_b1_t, r2_b2_t, r2_lasso_t, r2_clus_t,r2_true_t =  np.zeros(T), np.zeros(T), np.zeros(T),np.zeros(T), np.zeros(T),np.zeros(T)\n",
    "    \n",
    "    \n",
    "    for t in range(T):\n",
    "\n",
    "        # generate data\n",
    "        data = np.random.rand(n*obs,d)\n",
    "        data_test = np.random.rand(int(n*obs/2),d)\n",
    "\n",
    "        # generate clusters and betas\n",
    "        feature_dict = {}\n",
    "        clus_dict = {} # might not be used depending on the feature dict\n",
    "\n",
    "        for i in range(d):\n",
    "            # whether this feature should be estimated at the department level\n",
    "            feature_dict[i] = np.random.choice(['dept', 'clus', 'sku'], p = [p, q, 1-p-q])\n",
    "\n",
    "\n",
    "        items = set(range(n))\n",
    "\n",
    "        for i in range(z):\n",
    "            clus_items = random.sample(items,int(n/z))\n",
    "            clus_dict[i] = clus_items\n",
    "            items = items - set(clus_items)\n",
    "\n",
    "        # generate Beta\n",
    "        beta_dict = {}\n",
    "        num_cols = 0\n",
    "        for i in range(d):\n",
    "            if feature_dict[i] == 'dept':\n",
    "                beta_dict[i] = (np.random.random_sample() - 0.5) * 10\n",
    "                num_cols += 1\n",
    "            elif feature_dict[i] == 'clus':\n",
    "                beta_dict[i] = (np.random.random_sample(size = z) - 0.5) * 10\n",
    "                num_cols += z\n",
    "            else:\n",
    "                beta_dict[i] = (np.random.random_sample(size = n) - 0.5) * 10\n",
    "                num_cols += n\n",
    "\n",
    "        X_true = np.zeros((n*obs, num_cols))\n",
    "        X_test = np.zeros((int(n*obs/2), num_cols))\n",
    "\n",
    "        beta = np.zeros(num_cols)\n",
    "        count = 0\n",
    "        for i in range(d):\n",
    "            if feature_dict[i] == 'dept':\n",
    "                beta[count] = beta_dict[i]\n",
    "                X_true[:,count] = data[:,i]\n",
    "                X_test[:,count] = data_test[:,i]\n",
    "\n",
    "                count += 1\n",
    "\n",
    "            elif feature_dict[i] == 'clus':\n",
    "                for j in range(z):\n",
    "                    clus_items = clus_dict[j]\n",
    "                    for sku in clus_items:\n",
    "                        X_true[sku*obs:(sku+1)*obs, count] = data[sku*obs:(sku+1)*obs, i]\n",
    "                        X_test[int(sku*obs/2):int((sku+1)*obs/2), count] = data_test[int(sku*obs/2):int((sku+1)*obs/2), i]\n",
    "\n",
    "                    beta[count] = beta_dict[i][j]\n",
    "                    count += 1\n",
    "            else:\n",
    "                for j in range(n):\n",
    "                    X_true[j*obs:(j+1)*obs, count] = data[j*obs:(j+1)*obs, i]\n",
    "                    ######\n",
    "                    ######\n",
    "                    ####### \n",
    "                    X_test[int(j*obs/2):int((j+1)*obs/2), count] = data_test[int(j*obs/2):int((j+1)*obs/2), i]\n",
    "                    ######\n",
    "                    ######\n",
    "                    #######\n",
    "                    beta[count] = beta_dict[i][j]\n",
    "                    count += 1\n",
    "\n",
    "        epsilon = np.random.multivariate_normal(np.zeros(n*obs), np.identity(n*obs)*sigma)\n",
    "        epsilon_test = np.random.multivariate_normal(np.zeros(int(n*obs/2)), np.identity(int(n*obs/2))*sigma)\n",
    "        y = np.dot(X_true, beta) + epsilon\n",
    "        y_test = np.dot(X_test, beta) + epsilon_test\n",
    "        \n",
    "\n",
    "        # model fitting - b1\n",
    "        y_pred = []\n",
    "        ols_models = {}\n",
    "        for i in range(n):\n",
    "            model_i = OLS(y[i*obs:(i+1)*obs], data[i*obs:(i+1)*obs,:], hasconst = False)\n",
    "            ols_models[i] = model_i.fit()\n",
    "            y_pred += list(ols_models[i].predict(data_test[int(i*obs/2):int((i+1)*obs/2),:]))\n",
    "\n",
    "        r2_b1_t[t] = r2_score(y_test, np.array(y_pred))\n",
    "        \n",
    "\n",
    "\n",
    "        # model fitting - our method\n",
    "        aggre_level = []\n",
    "        clus_columns = []\n",
    "        all_coeff = np.zeros((n,d))\n",
    "        all_coeff[0,:] = ols_models[0].params\n",
    "        n_cols_alg = 0\n",
    "\n",
    "        for j in range(d):\n",
    "\n",
    "            # a n-1 vector recording if two betas have the same mean\n",
    "            test_j = np.zeros(n-1)\n",
    "\n",
    "            for i in range(1,n):\n",
    "                all_coeff[i,j] = ols_models[i].params[j]\n",
    "\n",
    "                z_stat = ( np.abs(ols_models[0].params[j] - ols_models[i].params[j]) / \n",
    "                          np.sqrt(np.square(ols_models[0].bse[j]) + np.square(ols_models[i].bse[j])) )\n",
    "                p_value = 1 - norm.cdf(z_stat)\n",
    "                if p_value >= 0.05:  #P-value ->0.05\n",
    "                    test_j[i-1] = 1\n",
    "\n",
    "            if np.sum(test_j) >= Ru*(n-1):\n",
    "                aggre_level.append('dept')\n",
    "                n_cols_alg += 1\n",
    "\n",
    "            elif np.sum(test_j) <= Rl*(n-1):\n",
    "                aggre_level.append('sku')\n",
    "                n_cols_alg += n\n",
    "\n",
    "            else:\n",
    "                aggre_level.append('clus')\n",
    "                clus_columns.append(j)\n",
    "                n_cols_alg += z\n",
    "\n",
    "        if len(clus_columns) > 0:\n",
    "            X_clus = all_coeff[:, clus_columns]\n",
    "            kmeans = KMeans(n_clusters=z, random_state=0).fit(X_clus)\n",
    "\n",
    "        X_alg = np.zeros((n*obs, n_cols_alg))\n",
    "        X_test = np.zeros((int(n*obs/2), n_cols_alg))\n",
    "\n",
    "        count = 0\n",
    "        for i in range(d):\n",
    "            if aggre_level[i] == 'dept':\n",
    "                X_alg[:,count] = data[:,i]\n",
    "                X_test[:,count] = data_test[:,i]\n",
    "                count += 1\n",
    "\n",
    "            elif aggre_level[i] == 'clus':\n",
    "                for j in range(z):\n",
    "                    clus_items = list(np.where(kmeans.labels_ == j)[0])\n",
    "                    for sku in clus_items:\n",
    "                        X_alg[sku*obs:(sku+1)*obs, count] = data[sku*obs:(sku+1)*obs, i]\n",
    "                        X_test[int(sku*obs/2):int((sku+1)*obs/2), count] = data_test[int(sku*obs/2):int((sku+1)*obs/2), i]\n",
    "\n",
    "\n",
    "                    count += 1\n",
    "            else:\n",
    "                for j in range(n):\n",
    "                    X_alg[j*obs:(j+1)*obs, count] = data[j*obs:(j+1)*obs, i]\n",
    "\n",
    "                    X_test[int(j*obs/2):int((j+1)*obs/2), count] = data_test[int(j*obs/2):int((j+1)*obs/2), i]\n",
    "\n",
    "                    count += 1\n",
    "\n",
    "\n",
    "        model_0 = OLS(y, X_alg, hasconst = False)\n",
    "        result = model_0.fit()\n",
    "        r2_alg_t[t] = r2_score(y_test, result.predict(X_test))\n",
    "        \n",
    "\n",
    "        # model fitting - b2\n",
    "        model_0 = OLS(y, data, hasconst = False)\n",
    "        result = model_0.fit()\n",
    "        r2_b2_t[t] = r2_score(y_test, result.predict(data_test))\n",
    "        \n",
    "\n",
    "        # model fitting - b1 Lasso\n",
    "        y_pred = []\n",
    "        for i in range(n):\n",
    "            model_i = LassoCV(alphas=[0.01,0.1,1,10,100],max_iter=10000).fit(data[i*obs:(i+1)*obs,:], y[i*obs:(i+1)*obs])\n",
    "            y_pred += list(model_i.predict(data_test[int(i*obs/2):int((i+1)*obs/2),:]))\n",
    "\n",
    "        r2_lasso_t[t] = r2_score(y_test, np.array(y_pred))\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        #other clustering\n",
    "        X_clus = np.zeros((n, d))\n",
    "        count = 0\n",
    "        y_pred = np.zeros(int(n*obs/2))\n",
    "        for i in range(n):\n",
    "            X_clus[count, :] = np.mean(data[i*obs:(i+1)*obs,:], axis = 0)\n",
    "            count += 1\n",
    "        \n",
    "        kmeans = KMeans(n_clusters=z, random_state=0).fit(X_clus)\n",
    "        for i in range(z):\n",
    "            clus_items = list(np.where(kmeans.labels_ == i)[0])\n",
    "            base_rows = np.array(list(range(obs)))\n",
    "            base_rows_test = np.array(list(range(int(obs/2))))\n",
    "            rows = []\n",
    "            test_rows = []\n",
    "            for j in clus_items:\n",
    "                rows += list(range( j*obs, (j+1)*obs ))\n",
    "                test_rows += list(range( j*int(obs/2), (j+1)*int(obs/2) ))\n",
    "            \n",
    "            model_i = OLS(y[np.ix_(rows)], data[np.ix_(rows)], hasconst = False).fit()\n",
    "            y_pred[np.ix_(test_rows)] = model_i.predict(data_test[np.ix_(test_rows)])\n",
    "\n",
    "        r2_clus_t[t] = r2_score(y_test, y_pred)\n",
    "\n",
    "    return np.mean(r2_alg_t), np.mean(r2_b1_t), np.mean(r2_b2_t), np.mean(r2_lasso_t), np.mean(r2_clus_t)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items: 10\n",
      "dac: 0.7290195171797351\n",
      "dec 0.6101685189027019\n",
      "items: 20\n",
      "dac: 0.7461761810453673\n",
      "dec 0.6281738361410864\n",
      "items: 30\n",
      "dac: 0.757023169662481\n",
      "dec 0.650619775051135\n",
      "items: 40\n",
      "dac: 0.7569947606516044\n",
      "dec 0.6609013275648219\n",
      "items: 50\n",
      "dac: 0.7535065107948333\n",
      "dec 0.6233787733097677\n",
      "items: 60\n",
      "dac: 0.753034924663497\n",
      "dec 0.6448733117721567\n",
      "items: 70\n",
      "dac: 0.7720804858996714\n",
      "dec 0.6595030142217233\n",
      "items: 80\n",
      "dac: 0.7617999065417758\n",
      "dec 0.6437168821307866\n",
      "items: 90\n",
      "dac: 0.7516541476906617\n",
      "dec 0.6550049354097953\n",
      "items: 100\n",
      "dac: 0.7722517151317366\n",
      "dec 0.6532746972601167\n",
      "items: 110\n",
      "dac: 0.7756364139192101\n",
      "dec 0.6574566261819048\n",
      "items: 120\n",
      "dac: 0.767118296776763\n",
      "dec 0.6334050974399046\n",
      "items: 130\n",
      "dac: 0.7803486753945701\n",
      "dec 0.6657158592125026\n"
     ]
    }
   ],
   "source": [
    "list_n = [i for i in range(10,160,10)]\n",
    "\n",
    "d=5\n",
    "p=2/3\n",
    "q=1/6\n",
    "sigma=1\n",
    "n=20\n",
    "obs=10\n",
    "\n",
    "r2_alg, r2_b1, r2_b2, r2_lasso, r2_clus = [], [], [], [],[]\n",
    "for n in list_n:\n",
    "    result_1, result_2, result_3, result_4,result_5 = fit_models_upd(0.9,0.6)\n",
    "    r2_alg.append(result_1)\n",
    "    r2_b1.append(result_2)\n",
    "    r2_b2.append(result_3)\n",
    "    r2_lasso.append(result_4)\n",
    "    r2_clus.append(result_5)\n",
    "    print(\"items:\",n)\n",
    "    print(\"dac:\",result_1)\n",
    "    print(\"dec\",result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list_n, r2_alg,\"--\",label = 'DAC')\n",
    "plt.plot(list_n, r2_b1,'',label = 'Decentralized')\n",
    "plt.plot(list_n, r2_b2,linestyle=(0, (5, 2, 1, 2)), dash_capstyle='round',label = 'Centralized')\n",
    "plt.plot(list_n, r2_clus,'y-o',markersize=3,label = 'Clustering')\n",
    "plt.plot(list_n, r2_lasso,\":\",label = 'Decentralized-Lasso')\n",
    "\n",
    "\n",
    "plt.legend(loc='best',frameon=False,prop={'size': 8})\n",
    "plt.xlabel('n')\n",
    "c1 = \"2\"\n",
    "label = r'$OOS$ R$^{{{}}}$ '.format(c1)\n",
    "plt.ylabel(label)\n",
    "\n",
    "\n",
    "plt.ylim(-0.4,1.1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
